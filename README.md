# ðŸ“ˆ ML Job Market Analyzer

A Python-based NLP project that extracts and visualizes machine learning skills from real-world job descriptions. This tool helps you understand which tools, technologies, and roles are in demand by parsing job posting text, extracting skills using NLP, and generating charts and word clouds.

---

## ðŸš€ Project Highlights

- ðŸ“„ Load job postings from Hugging Face datasets or Parquet files
- ðŸ§¹ Clean and normalize job descriptions
- ðŸ§  Extract in-demand ML skills using spaCy and custom keyword lists
- ðŸ“Š Visualize top skills via bar charts and word clouds
- ðŸ“¦ Export structured outputs for use in dashboards or analysis

---

## ðŸ—‚ Project Structure

```
MLJobMarketAnalyzer/
â”œâ”€â”€ data/                     # Dataset files (e.g., .parquet or .csv)
â”œâ”€â”€ output/                   # Exported CSVs and processed data
â”œâ”€â”€ src/                      # Core logic modules
â”‚   â”œâ”€â”€ preprocess.py         # Cleaning text and job descriptions
â”‚   â””â”€â”€ skill_extractor.py    # Skill extraction using NLP
â”œâ”€â”€ tests/                    # Unit tests for core modules
â”‚   â””â”€â”€ test_src_modules.py   # Tests for text cleaning and skill extraction
â”œâ”€â”€ main.py                   # Entry-point script for local processing
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # Project documentation (you are here)
```

---

## ðŸ§  Core Modules

### ðŸ”¹ `src/preprocess.py`
Functions:
- `clean_text(text)` â€“ Lowercases, removes punctuation, handles nulls
- `preprocess_dataframe(df)` â€“ Adds a `clean_description` column based on `description`

### ðŸ”¹ `src/skill_extractor.py`
Functions:
- `extract_skills(text)` â€“ Uses spaCy and a list of common ML skills to extract keywords

Example list includes:
```python
["python", "sql", "machine learning", "deep learning", "tensorflow", "keras", ...]
```

---

## ðŸ§ª Unit Tests

Tested with `unittest` in `tests/test_src_modules.py`:
- Cleans text inputs correctly
- Handles missing/empty strings
- Extracts skills from various realistic job postings

Run tests using:
```bash
python -m unittest discover -s tests
```

---

## ðŸ“Š Visual Output

- **Word cloud** of most common skills
- **Bar chart** for top N skills
- **CSV export** with extracted skills per job

---

## ðŸ’¾ How to Use

1. Install dependencies:
```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

2. (Optional) Load dataset from Hugging Face:
```python
from datasets import load_dataset

# Load and convert to DataFrame
ds = load_dataset("cmagganas/GenAI-job-postings-Dataset-sample")
df = ds['train'].to_pandas()
```

3. Process the data:
```bash
python main.py
```

4. Output:
- `output/sample_skills.csv` â€” extracted skills per job
- word cloud + bar chart (opens in matplotlib window)

---

## ðŸ“ˆ Use Cases

- ðŸ“š Educational tool to teach NLP + data cleaning
- ðŸ“Š Job market research and skill demand tracking
- ðŸ’¼ Add to GitHub portfolio to showcase data pipeline and NLP skills

---

## ðŸ§© Future Enhancements

- [ ] Add BERTopic or LDA topic modeling
- [ ] Streamlit dashboard interface
- [ ] Salary and location-based visualizations
- [ ] Integration with real-time job boards

---

## ðŸ‘¤ Author

**Poulami Nandi**  
Postdoctoral Researcher â€¢ Data Scientist â€¢ Quant Researcher  
ðŸ”— [LinkedIn](https://www.linkedin.com/in/poulami-nandi/)  
ðŸ“« nandi.poulami91@gmail.com

---

## ðŸ“œ License

This project is licensed under the **MIT License** â€” free to use, modify, and share.
